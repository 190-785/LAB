{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0183187-21f8-4f72-b18a-4b1e2257bcbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0183187-21f8-4f72-b18a-4b1e2257bcbc",
    "outputId": "394bb499-a941-4298-d1ad-544ee7277ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.21606\n",
      "Mean Squared Error (sklearn): 0.21606\n",
      "Mean Absolute Error:  0.398\n",
      "Mean Absolute Error (sklearn): 0.398\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# The prediction vector of the neural network\n",
    "y_pred=[0.6, 1.29, 1.99, 2.69, 3.4]\n",
    "\n",
    "# The ground truth label\n",
    "y_act= [1, 1, 2, 2, 4]\n",
    "\n",
    "# 1(a). Mean squared error (MSE)\n",
    "MSE = np.sum(np.square(np.subtract(y_act, y_pred)))/len(y_act)\n",
    "print(\"Mean Squared Error: \", MSE)\n",
    "\n",
    "# 1(b). MSE using sklearn\n",
    "mse_sklearn = mean_squared_error(y_act, y_pred)\n",
    "print(\"Mean Squared Error (sklearn):\", mse_sklearn)\n",
    "\n",
    "# 2(a). Mean Absolute Error (MAE)\n",
    "MAE = np.sum(np.absolute(np.subtract(y_act, y_pred)))/len(y_act)\n",
    "print(\"Mean Absolute Error: \",MAE)\n",
    "\n",
    "# 2(b). MAE using sklearn\n",
    "mae_sklearn = mean_absolute_error(y_act, y_pred)\n",
    "print(\"Mean Absolute Error (sklearn):\", mae_sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82fec6ba-0c51-47c5-bdf0-d14f6cbf73d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82fec6ba-0c51-47c5-bdf0-d14f6cbf73d9",
    "outputId": "ab044ef7-255a-4d4c-a5f9-6d2b36f7046d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (Manual): 0.398\n",
      "Mean Absolute Error (sklearn): 0.398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Example data: actual and predicted values\n",
    "y_pred = [0.6, 1.29, 1.99, 2.69, 3.4]\n",
    "y_true = [1, 1, 2, 2, 4]\n",
    "\n",
    "# 1. Manual calculation of MAE\n",
    "mae_manual = sum(abs(t - p) for t, p in zip(y_true, y_pred)) / len(y_true)\n",
    "print(\"Mean Absolute Error (Manual):\", mae_manual)\n",
    "\n",
    "# 2. Using sklearn for MAE\n",
    "mae_sklearn = mean_absolute_error(y_true, y_pred)\n",
    "print(\"Mean Absolute Error (sklearn):\", mae_sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de8e2f38-dd75-49a8-a505-dc648d1f0402",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de8e2f38-dd75-49a8-a505-dc648d1f0402",
    "outputId": "dc5fa976-e1d7-4a7e-8487-7a7ae02d8dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy Loss (Manual): 0.5756462732485114\n"
     ]
    }
   ],
   "source": [
    "# 3. Cross Entropy Loss Functionim\n",
    "import numpy as np\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy loss manually.\n",
    "\n",
    "    Args:\n",
    "        y_true (list or array): True labels (one-hot encoded).\n",
    "        y_pred (list or array): Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "        float: The cross-entropy loss.\n",
    "    \"\"\"\n",
    "    # Clip predictions to avoid log(0) error\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = -np.sum(y_true * np.log(y_pred)) / len(y_true)\n",
    "    return loss\n",
    "\n",
    "# Example data\n",
    "y_true = [1, 0, 0, 0]  # One-hot encoded for class 0\n",
    "y_pred = [0.1, 0.3, 0.4, 0.2]  # Predicted probabilities\n",
    "\n",
    "# Calculate cross-entropy loss\n",
    "loss = cross_entropy_loss(y_true, y_pred)\n",
    "print(\"Cross-Entropy Loss (Manual):\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c428fe17-effc-4ae9-971c-ac78e68b05ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c428fe17-effc-4ae9-971c-ac78e68b05ad",
    "outputId": "05712097-1c36-4f93-e9f4-937e1d911652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huber Loss (Manual): 0.1875\n",
      "Huber Loss (sklearn HuberRegressor): 0.11933839686008649\n"
     ]
    }
   ],
   "source": [
    "# 4. Huber Loss Function\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def huber_loss(y_true, y_pred, epsilon=1.0):\n",
    "    \"\"\"\n",
    "    Calculate the Huber loss manually.\n",
    "\n",
    "    Args:\n",
    "        y_true (list or array): Actual values.\n",
    "        y_pred (list or array): Predicted values.\n",
    "        epsilon (float): The threshold parameter (default=1.0).\n",
    "\n",
    "    Returns:\n",
    "        float: The Huber loss.\n",
    "    \"\"\"\n",
    "    error = np.array(y_true) - np.array(y_pred)\n",
    "    loss = np.where(np.abs(error) <= epsilon, 0.5 * error ** 2, epsilon * (np.abs(error) - 0.5 * epsilon))\n",
    "    return np.mean(loss)\n",
    "\n",
    "# Example data\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "# Manual Huber loss calculation\n",
    "huber_loss_manual = huber_loss(y_true, y_pred, epsilon=1.0)\n",
    "print(\"Huber Loss (Manual):\", huber_loss_manual)\n",
    "\n",
    "# Using sklearn HuberRegressor\n",
    "huber = HuberRegressor(epsilon=1.0)\n",
    "huber.fit(np.array(y_pred).reshape(-1, 1), y_true)\n",
    "y_predicted = huber.predict(np.array(y_pred).reshape(-1, 1))\n",
    "huber_loss_sklearn = huber_loss(y_true, y_predicted)\n",
    "print(\"Huber Loss (sklearn HuberRegressor):\", huber_loss_sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0d25f3d-17ce-44d7-af92-12db2b66a2ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0d25f3d-17ce-44d7-af92-12db2b66a2ca",
    "outputId": "132d2046-9126-46cd-82e8-98165658eb3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss (Manual): 0.425\n"
     ]
    }
   ],
   "source": [
    "# 5. Hinge Loss Function\n",
    "import numpy as np\n",
    "\n",
    "def hinge_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the hinge loss manually.\n",
    "\n",
    "    Args:\n",
    "        y_true (list or array): True labels (1 or -1).\n",
    "        y_pred (list or array): Predicted scores.\n",
    "\n",
    "    Returns:\n",
    "        float: The hinge loss.\n",
    "    \"\"\"\n",
    "    # Ensure labels are 1 or -1\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Hinge loss formula: max(0, 1 - y_true * y_pred)\n",
    "    loss = np.maximum(0, 1 - y_true * y_pred)\n",
    "\n",
    "    # Return mean loss\n",
    "    return np.mean(loss)\n",
    "\n",
    "# Example data\n",
    "y_true = [1, -1, 1, -1]  # True labels (+1 or -1)\n",
    "y_pred = [0.8, -0.5, 0.7, -0.3]  # Predicted scores\n",
    "\n",
    "# Calculate hinge loss\n",
    "loss = hinge_loss(y_true, y_pred)\n",
    "print(\"Hinge Loss (Manual):\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29fe53-d330-40e7-be3d-6d3f6dcba13b",
   "metadata": {
    "id": "6a29fe53-d330-40e7-be3d-6d3f6dcba13b"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "zip(y_true, y_pred):\n",
    "\n",
    "The zip() function combines two lists element-wise into pairs.\n",
    "For example:\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "list(zip(y_true, y_pred))\n",
    "# Output: [(3, 2.5), (-0.5, 0.0), (2, 2), (7, 8)]\n",
    "for t, p in zip(...):\n",
    "\n",
    "This loop unpacks each pair into variables t (true value) and p (predicted value).\n",
    "Example iterations:\n",
    "Iteration 1: t = 3, p = 2.5\n",
    "Iteration 2: t = -0.5, p = 0.0\n",
    "Iteration 3: t = 2, p = 2\n",
    "Iteration 4: t = 7, p = 8\n",
    "abs(t - p):\n",
    "\n",
    "Calculates the absolute difference between each true and predicted value:\n",
    "abs(3 - 2.5) = 0.5\n",
    "abs(-0.5 - 0.0) = 0.5\n",
    "abs(2 - 2) = 0\n",
    "abs(7 - 8) = 1\n",
    "sum(...):\n",
    "\n",
    "The sum() function adds all these absolute differences together:\n",
    "\n",
    "0.5+0.5+0+1=2.0\n",
    "/ len(y_true):\n",
    "\n",
    "Finally, we divide by the number of elements in y_true to get the average difference:\n",
    "0.5\n",
    "This result, 0.5, is the Mean Absolute Error (MAE), which measures the average magnitude of prediction errors. Smaller MAE values indicate more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf36b2-1f99-4628-8e46-e5247e0bb2e5",
   "metadata": {
    "id": "bacf36b2-1f99-4628-8e46-e5247e0bb2e5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b51e5-e2c1-41ea-8a06-e4a9eca022a3",
   "metadata": {
    "id": "298b51e5-e2c1-41ea-8a06-e4a9eca022a3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
